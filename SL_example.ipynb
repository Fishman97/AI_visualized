{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759c9fbe",
   "metadata": {},
   "source": [
    "\n",
    "# Supervised Learning example with MNIST dataset\n",
    "\n",
    "This notebook implements a convolutional neural network (CNN) on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04df03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, time\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ipycanvas import Canvas\n",
    "from ipywidgets import VBox, HBox, Button, Output, Layout\n",
    "from IPython.display import display, clear_output, IFrame\n",
    "import netron\n",
    "\n",
    "device = (\n",
    "    torch.device(\"mps\") if torch.backends.mps.is_available()\n",
    "    else torch.device(\"cuda\") if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(\"Using device:\", device)\n",
    "torch.manual_seed(42); np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d6d36b",
   "metadata": {},
   "source": [
    "### Data import and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15ffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_ds = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform_train)\n",
    "test_ds  = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=512, shuffle=False)\n",
    "\n",
    "print(\"Training dataset: \"+ str(len(train_ds)) + \" elements\")\n",
    "print(\"Test dataset: \"+ str(len(test_ds)) + \" elements\")\n",
    "\n",
    "fig, axes = plt.subplots(5, 8, figsize=(12, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(train_ds[i][0].squeeze(), cmap='gray')\n",
    "    ax.set_title(f\"Label: {train_ds[i][1]}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e413e47c",
   "metadata": {},
   "source": [
    "## Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Creation\n",
    "class TinyConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # conv/pool stack: input [1,28,28] -> conv1 -> pool -> conv2 -> pool\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)   # -> [16,24,24]\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)  # -> [32,8,8] after pool\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        # classifier\n",
    "        self.fc1 = nn.Linear(32 * 4 * 4, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x, return_activations=False):\n",
    "        # x: [B,1,28,28]\n",
    "        c1 = F.relu(self.conv1(x))   # [B,16,24,24]\n",
    "        p1 = self.pool(c1)           # [B,16,12,12]\n",
    "        c2 = F.relu(self.conv2(p1))  # [B,32,8,8]\n",
    "        p2 = self.pool(c2)           # [B,32,4,4]\n",
    "        flat = p2.view(p2.size(0), -1)\n",
    "        a1 = F.relu(self.fc1(flat))\n",
    "        logits = self.fc2(a1)\n",
    "        if return_activations:\n",
    "            return logits, {\n",
    "                'conv1': c1.detach().cpu().numpy(),\n",
    "                'conv2': c2.detach().cpu().numpy(),\n",
    "                'fc1': a1.detach().cpu().numpy(),\n",
    "                'logits': logits.detach().cpu().numpy()\n",
    "            }\n",
    "        return logits\n",
    "\n",
    "model = TinyConvNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(\"Number of model parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9561fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train(); n=0; loss_sum=0.0; acc_sum=0.0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        loss.backward(); optimizer.step()\n",
    "        bs = yb.size(0); n += bs\n",
    "        loss_sum += loss.item()*bs\n",
    "        acc_sum  += (logits.argmax(1)==yb).float().sum().item()\n",
    "    return loss_sum/n, acc_sum/n\n",
    "\n",
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval(); n=0; loss_sum=0.0; acc_sum=0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            bs = yb.size(0); n += bs\n",
    "            loss_sum += loss.item()*bs\n",
    "            acc_sum  += (logits.argmax(1)==yb).float().sum().item()\n",
    "    return loss_sum/n, acc_sum/n\n",
    "\n",
    "EPOCHS=3\n",
    "tr_hist={\"loss\":[], \"acc\":[]}; te_hist={\"loss\":[], \"acc\":[]}\n",
    "for ep in range(1,EPOCHS+1):\n",
    "    tr_loss,tr_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    te_loss,te_acc = evaluate(model, test_loader,  criterion)\n",
    "    tr_hist[\"loss\"].append(tr_loss); tr_hist[\"acc\"].append(tr_acc)\n",
    "    te_hist[\"loss\"].append(te_loss); te_hist[\"acc\"].append(te_acc)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Epoch {ep}/{EPOCHS}  | train {tr_loss:.4f}/{tr_acc:.4f}  test {te_loss:.4f}/{te_acc:.4f}\")\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,3))\n",
    "    ax1.plot(tr_hist[\"loss\"],label=\"train\"); ax1.plot(te_hist[\"loss\"],label=\"test\"); ax1.set_title(\"Loss\"); ax1.legend()\n",
    "    ax2.plot(tr_hist[\"acc\"],label=\"train\");  ax2.plot(te_hist[\"acc\"],label=\"test\");  ax2.set_title(\"Accuracy\"); ax2.legend()\n",
    "    plt.show()\n",
    "print(\"Training done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62411daa",
   "metadata": {},
   "source": [
    "## Test and interactive prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcf36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Draw area via ipycanvas (smaller canvas, white background) ---\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "canvas = Canvas(width=200, height=200, sync_image_data=True)\n",
    "canvas.layout.width  = '200px'\n",
    "canvas.layout.height = '200px'\n",
    "# fill white background so strokes (black on white) are visible\n",
    "canvas.fill_style = 'white'\n",
    "canvas.fill_rect(0, 0, canvas.width, canvas.height)\n",
    "# draw a light border on the same canvas so coords align\n",
    "canvas.stroke_style = 'lightgray'\n",
    "canvas.stroke_rect(0.5, 0.5, canvas.width-1, canvas.height-1)\n",
    "\n",
    "# Create a local PIL buffer that mirrors the visible canvas — reliable source for predictions\n",
    "buf_img = Image.new('L', (canvas.width, canvas.height), color=255)  # 'L' gray, 255=white\n",
    "buf_draw = ImageDraw.Draw(buf_img)\n",
    "\n",
    "# Simple drawing controls — fixed brush size (no slider)\n",
    "BRUSH_SIZE = 18\n",
    "btn_clear   = Button(description=\"Clear\")\n",
    "# single output combining preview + probabilities to avoid duplicate figures\n",
    "pred_out = Output()\n",
    "\n",
    "# Use explicit mouse-down / mouse-up handlers and robust coord parsing\n",
    "is_drawing = {'val': False}\n",
    "\n",
    "# Throttle predictions: allow up to 1 prediction per second\n",
    "PRED_INTERVAL = 1.0  # seconds\n",
    "_last_pred_time = 0.0\n",
    "\n",
    "def _get_xy(args):\n",
    "    if len(args) >= 2 and isinstance(args[0], (int, float)) and isinstance(args[1], (int, float)):\n",
    "        return args[0], args[1]\n",
    "    if len(args) >= 1 and isinstance(args[0], dict):\n",
    "        ev = args[0]\n",
    "        return ev.get('x', None), ev.get('y', None)\n",
    "    return None, None\n",
    "\n",
    "def _draw_circle_on_buffer(x, y, r):\n",
    "    r = int(round(r))\n",
    "    bbox = (int(round(x - r)), int(round(y - r)), int(round(x + r)), int(round(y + r)))\n",
    "    buf_draw.ellipse(bbox, fill=0)\n",
    "\n",
    "def on_mouse_down(*args):\n",
    "    x, y = _get_xy(args)\n",
    "    if x is None:\n",
    "        return\n",
    "    is_drawing['val'] = True\n",
    "    radius = BRUSH_SIZE/2\n",
    "    canvas.fill_style = 'black'  # draw black strokes\n",
    "    canvas.fill_circle(x, y, radius)\n",
    "    _draw_circle_on_buffer(x, y, radius)\n",
    "    try:\n",
    "        predict_and_show()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def on_mouse_up(*args):\n",
    "    is_drawing['val'] = False\n",
    "    try:\n",
    "        predict_and_show(True)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def on_mouse_move(*args):\n",
    "    x, y = _get_xy(args)\n",
    "    if x is None:\n",
    "        return\n",
    "    if is_drawing['val']:\n",
    "        radius = BRUSH_SIZE/2\n",
    "        canvas.fill_style = 'black'\n",
    "        canvas.fill_circle(x, y, radius)\n",
    "        _draw_circle_on_buffer(x, y, radius)\n",
    "        try:\n",
    "            predict_and_show()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "canvas.on_mouse_down(on_mouse_down)\n",
    "canvas.on_mouse_up(on_mouse_up)\n",
    "canvas.on_mouse_move(on_mouse_move)\n",
    "\n",
    "def clear_canvas(*_):\n",
    "    # clear visible canvas and reset PIL buffer\n",
    "    canvas.fill_style = 'white'\n",
    "    canvas.fill_rect(0, 0, canvas.width, canvas.height)\n",
    "    canvas.stroke_style = 'lightgray'\n",
    "    canvas.stroke_rect(0.5, 0.5, canvas.width-1, canvas.height-1)\n",
    "    global buf_img, buf_draw\n",
    "    buf_img = Image.new('L', (canvas.width, canvas.height), color=255)\n",
    "    buf_draw = ImageDraw.Draw(buf_img)\n",
    "    # clear the output pane but keep it visible\n",
    "    pred_out.clear_output(wait=True)\n",
    "    # redraw initial empty preview/probs\n",
    "    try:\n",
    "        predict_and_show()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def get_28x28_tensor():\n",
    "    # Use the local PIL buffer (buf_img) as the authoritative image of strokes\n",
    "    img = buf_img.copy().resize((28,28), Image.LANCZOS)\n",
    "    arr = np.array(img, dtype=np.float32) / 255.0  # 0=black stroke, 1=white background\n",
    "    # we want strokes=1.0, background=0.0 for the model input\n",
    "    x = 1.0 - arr\n",
    "    return torch.from_numpy(x)[None, None, ...].float()  # [1,1,28,28]\n",
    "\n",
    "def _predict_and_show_now(x):\n",
    "    # helper that actually runs prediction and updates outputs\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(x.to(device))\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    pred = int(np.argmax(probs))\n",
    "\n",
    "    # update single combined output (image left, probabilities right)\n",
    "    with pred_out:\n",
    "        pred_out.clear_output(wait=True)\n",
    "        fig, (ax_im, ax_bar) = plt.subplots(1,2, figsize=(6,3), gridspec_kw={'width_ratios':[1,1.2]})\n",
    "        # image (no title 'Pred')\n",
    "        ax_im.imshow(x[0,0].cpu(), cmap='gray')\n",
    "        ax_im.axis('off')\n",
    "        # probability bar chart\n",
    "        ax_bar.bar(np.arange(10), probs, color='tab:blue')\n",
    "        ax_bar.set_title('Class probabilities')\n",
    "        ax_bar.set_xticks(np.arange(10))\n",
    "        ax_bar.set_ylim(0,1)\n",
    "        # visually mark predicted class on bar chart\n",
    "        ax_bar.get_children()[pred].set_color('tab:orange')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def predict_and_show(force = False):\n",
    "    \"\"\"Throttle predictions: only run if at least PRED_INTERVAL seconds have passed since last run.\"\"\"\n",
    "    global _last_pred_time\n",
    "    now = time.time()\n",
    "    if (now - _last_pred_time) < PRED_INTERVAL and not force:\n",
    "        # skip this prediction to limit frequency\n",
    "        return\n",
    "    _last_pred_time = now\n",
    "    x = get_28x28_tensor()\n",
    "    try:\n",
    "        _predict_and_show_now(x)\n",
    "    except Exception:\n",
    "        # guard: do not propagate UI errors\n",
    "        pass\n",
    "\n",
    "btn_clear.on_click(clear_canvas)\n",
    "\n",
    "# Layout: canvas on the left, combined preview+probs + clear button on the right\n",
    "ui = HBox([canvas, VBox([ pred_out, btn_clear])], layout=Layout(width='600px'))\n",
    "display(ui)\n",
    "\n",
    "# show initial empty prediction so UI is populated before drawing\n",
    "try:\n",
    "    predict_and_show()\n",
    "except Exception:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-viz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
